{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Using Llama 3.2 90B LLM with Python & Groq for diverse real-world tasks using Prompt Engineering"],"metadata":{"id":"fb6rdwlCsCGt"}},{"cell_type":"markdown","source":["In this notebook you will use Meta Llama 3.2 90B LLM via Groq to solve:\n","\n","- Task 1: Zero-shot Classification\n","- Task 2: Few-shot Classification\n","- Task 3: Coding Tasks - Python\n","- Task 4: Coding Tasks - SQL\n","- Task 5: Information Extraction\n","- Task 6: Closed-Domain Question Answering\n","- Task 7: Open-Domain Question Answering\n","- Task 8: Document Summarization\n","- Task 9: Transformation\n","- Task 10: Translation\n","\n","\n","\n","___Created By: Dipanjan (DJ)___"],"metadata":{"id":"XTzBUFWQ-OWj"}},{"cell_type":"markdown","source":["## Install Groq Cloud dependencies"],"metadata":{"id":"L1KvMtf54l0d"}},{"cell_type":"code","source":["!pip install groq==0.13.0"],"metadata":{"id":"2evPp14fy258","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14699ca3-e775-4195-f109-292c7d77c6c6","executionInfo":{"status":"ok","timestamp":1734091612342,"user_tz":-330,"elapsed":11079,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting groq==0.13.0\n","  Downloading groq-0.13.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (2.10.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.0) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq==0.13.0) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq==0.13.0) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq==0.13.0) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq==0.13.0) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.13.0) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq==0.13.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq==0.13.0) (2.27.1)\n","Downloading groq-0.13.0-py3-none-any.whl (108 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: groq\n","Successfully installed groq-0.13.0\n"]}]},{"cell_type":"markdown","source":["## Load Groq API Credentials\n"],"metadata":{"id":"qvzfEaGRr6iJ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"10a5f4b3-c19f-4643-b832-7bd7f364a268","id":"-Tb0TO3Nr6iK","executionInfo":{"status":"ok","timestamp":1734091629402,"user_tz":-330,"elapsed":8451,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Groq API Key: ··········\n"]}],"source":["from getpass import getpass\n","\n","groq_key = getpass(\"Enter your Groq API Key: \")"]},{"cell_type":"markdown","source":["## Use Groq for Prompting Open Source LLMs"],"metadata":{"id":"HabRE4PZAz80"}},{"cell_type":"code","source":["from groq import Groq\n","\n","groq_client = Groq(api_key=groq_key)"],"metadata":{"id":"nhJdZLOLvBzs","executionInfo":{"status":"ok","timestamp":1734091635264,"user_tz":-330,"elapsed":2934,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Find more models here\n","# https://console.groq.com/settings/limits\n","def get_completion(prompt, model=\"llama-3.2-90b-vision-preview\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = groq_client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # degree of randomness of the model's output\n","    )\n","    return response.choices[0].message.content"],"metadata":{"id":"ZWGDT9m2A2GI","executionInfo":{"status":"ok","timestamp":1734091694525,"user_tz":-330,"elapsed":346,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Let's try out the Llama 3.2 90B model!"],"metadata":{"id":"1TFZjzuGjCOw"}},{"cell_type":"code","source":["from IPython.display import Markdown, display\n","\n","response = get_completion(prompt='Explain Generative AI in 2 bullet points')\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"KK-kjmMoi5rO","outputId":"321f5484-904d-4103-ecd1-742206af9809","executionInfo":{"status":"ok","timestamp":1734091698251,"user_tz":-330,"elapsed":1131,"user":{"displayName":"Dipanjan “DJ” Sarkar","userId":"05135987707016476934"}}},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Here are 2 bullet points explaining Generative AI:\n\n• **Creating new content**: Generative AI is a type of artificial intelligence that can generate new, original content, such as text, images, music, or videos, based on patterns and structures learned from existing data. This is achieved through complex algorithms and machine learning models that can mimic human creativity.\n\n• **Learning from data**: Generative AI models are trained on large datasets, which enable them to learn the underlying patterns, relationships, and structures of the data. This training allows the models to generate new content that is similar in style, tone, and quality to the original data, but with unique characteristics and variations."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 1: Zero-shot Classification\n","\n","This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text without providing any examples.\n","\n"],"metadata":{"id":"AeDkpvGDhMGV"}},{"cell_type":"code","source":["reviews = [\n","    f\"\"\"\n","    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n","    The sound quality is impressively clear with just the right amount of bass.\n","    It's also waterproof, which tested true during a recent splashing incident.\n","    Though it's compact, the volume can really fill the space.\n","    The price was a bargain for such high-quality sound.\n","    Shipping was also on point, arriving two days early in secure packaging.\n","    \"\"\",\n","    f\"\"\"\n","    Needed a new kitchen blender, but this model has been a nightmare.\n","    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n","    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n","    I thought the brand meant quality, but this product has proven me wrong.\n","    Plus, it arrived three days late. Definitely not worth the expense.\n","    \"\"\"\n","]"],"metadata":{"id":"hRbBZB57hT0G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["responses = []\n","\n","for review in reviews:\n","  prompt = f\"\"\"\n","              Act as a product review analyst.\n","              Given the following review,\n","              Display the overall sentiment for the review as only one of the following:\n","              Positive, Negative OR Neutral\n","\n","              ```{review}```\n","              \"\"\"\n","  response = get_completion(prompt)\n","  responses.append(response)"],"metadata":{"id":"jZwPaViatl7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for review, response in zip(reviews, responses):\n","  print('Review:', review)\n","  print('Sentiment:', response)\n","  print('------')\n","  print('\\n')"],"metadata":{"id":"EdUFkKAmtmBj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09bb4d2e-9ee9-401b-8f0d-eca4759a67b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review: \n","    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n","    The sound quality is impressively clear with just the right amount of bass.\n","    It's also waterproof, which tested true during a recent splashing incident.\n","    Though it's compact, the volume can really fill the space.\n","    The price was a bargain for such high-quality sound.\n","    Shipping was also on point, arriving two days early in secure packaging.\n","    \n","Sentiment: Positive\n","------\n","\n","\n","Review: \n","    Needed a new kitchen blender, but this model has been a nightmare.\n","    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n","    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n","    I thought the brand meant quality, but this product has proven me wrong.\n","    Plus, it arrived three days late. Definitely not worth the expense.\n","    \n","Sentiment: Negative\n","------\n","\n","\n"]}]},{"cell_type":"markdown","source":["## Task 2: Few-shot Classification\n","\n","This prompt tests an LLM's text classification capabilities by prompting it to classify a piece of text by providing a few examples of inputs and outputs.\n","\n"],"metadata":{"id":"6WC6aycZ9Qe3"}},{"cell_type":"code","source":["responses = []\n","\n","for review in reviews:\n","  prompt = f\"\"\"\n","              Act as a product review analyst.\n","              Given the following review,\n","              Display only the overall sentiment for the review:\n","\n","              Try to classify it by using the following examples as a reference:\n","\n","              Review: Just received the Laptop I ordered for work, and it's amazing.\n","              Sentiment: 😊\n","\n","              Review: Needed a new mechanical keyboard, but this model has been totally disappointing.\n","              Sentiment: 😡\n","\n","              Review: ```{review}```\n","              \"\"\"\n","  response = get_completion(prompt)\n","  responses.append(response)"],"metadata":{"id":"kQZdygfUoXGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for review, response in zip(reviews, responses):\n","  print('Review:', review)\n","  print('Sentiment:', response)\n","  print('------')\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OCsMzs3QodqR","outputId":"97925186-c76c-46bf-8aeb-9aa10039a011"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Review: \n","    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n","    The sound quality is impressively clear with just the right amount of bass.\n","    It's also waterproof, which tested true during a recent splashing incident.\n","    Though it's compact, the volume can really fill the space.\n","    The price was a bargain for such high-quality sound.\n","    Shipping was also on point, arriving two days early in secure packaging.\n","    \n","Sentiment: 😊\n","------\n","\n","\n","Review: \n","    Needed a new kitchen blender, but this model has been a nightmare.\n","    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n","    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n","    I thought the brand meant quality, but this product has proven me wrong.\n","    Plus, it arrived three days late. Definitely not worth the expense.\n","    \n","Sentiment: 😡\n","------\n","\n","\n"]}]},{"cell_type":"markdown","source":["## Task 3: Coding Tasks - Python\n","\n","This prompt tests an LLM's capabilities for generating python code based on various tasks\n"],"metadata":{"id":"HEKTyfWf9cxY"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Act as an expert in generating python code\n","\n","Your task is to generate python code\n","to build a Chain of Though prompt pattern using\n","the openai python library\n","\"\"\"\n","response = get_completion(prompt)"],"metadata":{"id":"6xawr-Co9b0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Markdown, display\n","\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2Cenat0G9-Bw","outputId":"bcfc867a-a5ad-4195-ddb1-b417582da25f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Chain of Thought Prompt Pattern using OpenAI Python Library**\n===========================================================\n\nThe Chain of Thought prompt pattern is a technique used to generate more accurate and informative responses from language models. It involves breaking down a complex problem into a series of simpler, more manageable steps, and then using the output from each step as the input for the next step.\n\nHere's an example of how you can implement the Chain of Thought prompt pattern using the OpenAI Python library:\n\n```python\nimport openai\n\n# Initialize the OpenAI API client\nopenai.api_key = \"YOUR_OPENAI_API_KEY\"\n\ndef chain_of_thought_prompt(prompt, steps):\n    \"\"\"\n    Generate a Chain of Thought prompt pattern using the OpenAI API.\n\n    Args:\n        prompt (str): The initial prompt to start the chain of thought.\n        steps (list): A list of steps to break down the problem into.\n\n    Returns:\n        str: The final response from the OpenAI API.\n    \"\"\"\n    # Initialize the response variable\n    response = \"\"\n\n    # Loop through each step in the chain of thought\n    for i, step in enumerate(steps):\n        # If it's the first step, use the initial prompt\n        if i == 0:\n            input_prompt = prompt\n        # Otherwise, use the previous response as the input prompt\n        else:\n            input_prompt = response\n\n        # Append the current step to the input prompt\n        input_prompt += f\" {step}\"\n\n        # Generate a response from the OpenAI API\n        response = openai.Completion.create(\n            engine=\"text-davinci-003\",\n            prompt=input_prompt,\n            max_tokens=2048,\n            temperature=0.7,\n            top_p=1,\n            frequency_penalty=0,\n            presence_penalty=0\n        )[\"choices\"][0][\"text\"]\n\n    # Return the final response\n    return response\n\n# Example usage\nprompt = \"Write a short story about a character who discovers a hidden world.\"\nsteps = [\n    \"First, describe the character's ordinary world.\",\n    \"Next, describe the event that leads the character to discover the hidden world.\",\n    \"Then, describe the character's initial reaction to the hidden world.\",\n    \"Finally, describe the character's journey as they explore the hidden world.\"\n]\n\nresponse = chain_of_thought_prompt(prompt, steps)\nprint(response)\n```\n\n**How it works:**\n\n1. The `chain_of_thought_prompt` function takes in an initial prompt and a list of steps to break down the problem into.\n2. It initializes a response variable to store the output from each step.\n3. It loops through each step in the chain of thought, using the previous response as the input prompt for the next step.\n4. For each step, it appends the current step to the input prompt and generates a response from the OpenAI API using the `openai.Completion.create` method.\n5. It returns the final response from the OpenAI API.\n\n**Tips and Variations:**\n\n* You can adjust the `max_tokens`, `temperature`, `top_p`, `frequency_penalty`, and `presence_penalty` parameters to fine-tune the response generation.\n* You can use different OpenAI engines, such as `text-curie-001` or `text-babbage-001`, to generate responses with different styles and tones.\n* You can add more steps to the chain of thought to break down complex problems into even simpler, more manageable parts.\n* You can use this technique to generate responses for a wide range of tasks, from creative writing to problem-solving and decision-making."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 4: Coding Tasks - SQL\n","\n","This prompt tests an LLM's capabilities for generating SQL code based on various tasks"],"metadata":{"id":"0JoSF5wb_Imw"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Act as an expert in generating SQL code.\n","\n","Understand the following schema of the database tables carefully:\n","Table departments, columns = [DepartmentId, DepartmentName]\n","Table employees, columns = [EmployeeId, EmployeeName, DepartmentId]\n","Table salaries, columns = [EmployeeId, Salary]\n","\n","Create a MySQL query for the employee with max salary in the 'IT' Department.\n","\"\"\"\n","response = get_completion(prompt)"],"metadata":{"id":"4XKGZIG3_Tjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":980},"id":"4cFqsBtSA7Wx","outputId":"db285445-880a-4c82-94ac-5174d3b36d6a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**SQL Query to Find Employee with Max Salary in 'IT' Department**\n\nTo find the employee with the maximum salary in the 'IT' department, we need to join the `employees`, `salaries`, and `departments` tables based on their respective IDs. Here's the MySQL query to achieve this:\n\n```sql\nSELECT e.EmployeeName, s.Salary\nFROM employees e\nJOIN salaries s ON e.EmployeeId = s.EmployeeId\nJOIN departments d ON e.DepartmentId = d.DepartmentId\nWHERE d.DepartmentName = 'IT'\nORDER BY s.Salary DESC\nLIMIT 1;\n```\n\n**Explanation:**\n\n1. We join the `employees` table with the `salaries` table on the `EmployeeId` column to get the salary information for each employee.\n2. We then join the resulting table with the `departments` table on the `DepartmentId` column to filter employees by department.\n3. We apply a filter to only consider employees in the 'IT' department using the `WHERE` clause.\n4. We sort the resulting table in descending order by salary using the `ORDER BY` clause.\n5. Finally, we use the `LIMIT 1` clause to return only the employee with the maximum salary.\n\n**Example Use Case:**\n\nSuppose we have the following data in our tables:\n\n`departments` table:\n\n| DepartmentId | DepartmentName |\n| --- | --- |\n| 1 | IT |\n| 2 | Sales |\n| 3 | Marketing |\n\n`employees` table:\n\n| EmployeeId | EmployeeName | DepartmentId |\n| --- | --- | --- |\n| 1 | John Doe | 1 |\n| 2 | Jane Smith | 1 |\n| 3 | Bob Johnson | 2 |\n\n`salaries` table:\n\n| EmployeeId | Salary |\n| --- | --- |\n| 1 | 100000 |\n| 2 | 120000 |\n| 3 | 80000 |\n\nRunning the above query would return:\n\n| EmployeeName | Salary |\n| --- | --- |\n| Jane Smith | 120000 |\n\nThis indicates that Jane Smith is the employee with the maximum salary in the 'IT' department."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 5: Information Extraction\n","\n","This prompt tests an LLM's capabilities for extracting and analyzing key entities from documents"],"metadata":{"id":"-mck_SlcM3bG"}},{"cell_type":"code","source":["clinical_note = \"\"\"\n","60-year-old man in NAD with a h/o CAD, DM2, asthma, pharyngitis, SBP,\n","and HTN on altace for 8 years awoke from sleep around 1:00 am this morning\n","with a sore throat and swelling of the tongue.\n","He came immediately to the ED because he was having difficulty swallowing and\n","some trouble breathing due to obstruction caused by the swelling.\n","He did not have any associated SOB, chest pain, itching, or nausea.\n","He has not noticed any rashes.\n","He says that he feels like it is swollen down in his esophagus as well.\n","He does not recall vomiting but says he might have retched a bit.\n","In the ED he was given 25mg benadryl IV, 125 mg solumedrol IV,\n","and pepcid 20 mg IV.\n","Family history of CHF and esophageal cancer (father).\n","\"\"\""],"metadata":{"id":"UxciK2wsIw3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = f\"\"\"\n","Act as an expert in analyzing and understanding clinical doctor notes in healthcare.\n","Extract all symptoms only from the clinical note information below.\n","Differentiate between symptoms that are present vs. absent.\n","Give me the probability (high/ medium/ low) of how sure you are about the result.\n","Add a note on the probabilities and why you think so.\n","\n","Output as a markdown table with the following columns,\n","all symptoms should be expanded and no acronyms unless you don't know:\n","\n","Symptoms | Present/Denies | Probability.\n","\n","Also expand all acronyms.\n","Output that also as a separate appendix table in Markdown.\n","\n","Clinical Note:\n","```{clinical_note}```\n","\"\"\"\n","response = get_completion(prompt)"],"metadata":{"id":"GcazKzm0JGKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"pqXCxmtEJl4h","outputId":"390864ea-6ac4-46b2-d090-f25e34fbe73d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Symptoms Table**\n| Symptoms | Present/Denies | Probability |\n| --- | --- | --- |\n| Sore throat | Present | High |\n| Swelling of the tongue | Present | High |\n| Difficulty swallowing | Present | High |\n| Trouble breathing | Present | High |\n| Shortness of breath (SOB) | Denies | Medium |\n| Chest pain | Denies | Medium |\n| Itching | Denies | Medium |\n| Nausea | Denies | Medium |\n| Rashes | Denies | Medium |\n| Swelling in the esophagus | Present | Medium |\n| Vomiting | Denies (possible retching) | Low |\n\n**Note on Probabilities:**\n- High probability: The symptoms are explicitly mentioned in the clinical note as being present.\n- Medium probability: The symptoms are explicitly mentioned in the clinical note as being absent, but the patient's condition might still be related to these symptoms.\n- Low probability: The symptom is not explicitly mentioned as being present or absent, but there is a mention of a related action (retching) that might be associated with the symptom.\n\n**Appendix Table: Expanded Acronyms**\n| Acronym | Expanded Form |\n| --- | --- |\n| NAD | No Acute Distress |\n| CAD | Coronary Artery Disease |\n| DM2 | Diabetes Mellitus Type 2 |\n| SBP | Systolic Blood Pressure |\n| HTN | Hypertension |\n| SOB | Shortness of Breath |\n| ED | Emergency Department |\n| IV | Intravenous |\n| CHF | Congestive Heart Failure |"},"metadata":{}}]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYMRl7HIpzYF","outputId":"fb862396-8da5-434b-d584-44443e2ca2da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["**Symptoms Table**\n","| Symptoms | Present/Denies | Probability |\n","| --- | --- | --- |\n","| Sore throat | Present | High |\n","| Swelling of the tongue | Present | High |\n","| Difficulty swallowing | Present | High |\n","| Trouble breathing | Present | High |\n","| Shortness of breath (SOB) | Denies | Medium |\n","| Chest pain | Denies | Medium |\n","| Itching | Denies | Medium |\n","| Nausea | Denies | Medium |\n","| Rashes | Denies | Medium |\n","| Swelling in the esophagus | Present | Medium |\n","| Vomiting | Denies (possible retching) | Low |\n","\n","**Note on Probabilities:**\n","- High probability: The symptoms are explicitly mentioned in the clinical note as being present.\n","- Medium probability: The symptoms are explicitly mentioned in the clinical note as being absent, but the patient's condition might still be related to these symptoms.\n","- Low probability: The symptom is not explicitly mentioned as being present or absent, but there is a mention of a related action (retching) that might be associated with the symptom.\n","\n","**Appendix Table: Expanded Acronyms**\n","| Acronym | Expanded Form |\n","| --- | --- |\n","| NAD | No Acute Distress |\n","| CAD | Coronary Artery Disease |\n","| DM2 | Diabetes Mellitus Type 2 |\n","| SBP | Systolic Blood Pressure |\n","| HTN | Hypertension |\n","| SOB | Shortness of Breath |\n","| ED | Emergency Department |\n","| IV | Intravenous |\n","| CHF | Congestive Heart Failure |\n"]}]},{"cell_type":"markdown","source":["## Task 6: Closed-Domain Question Answering\n","\n","Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question. Question Answering can be open-domain QA or closed-domain QA depending on whether the LLM is provided with the relevant context or not.\n","\n","In the case of closed-domain QA, a question along with relevant context is given. Here the context is nothing but the relevant text which ideally should have the answer. Just like a RAG workflow."],"metadata":{"id":"_jucY6L9w14Z"}},{"cell_type":"code","source":["report = \"\"\"\n","Three quarters (77%) of the population saw an increase in their regular outgoings over the past year,\n","according to findings from our recent consumer survey. In contrast, just over half (54%) of respondents\n","had an increase in their salary, which suggests that the burden of costs outweighing income remains for\n","most. In total, across the 2,500 people surveyed, the increase in outgoings was 18%, three times higher\n","than the 6% increase in income.\n","\n","Despite this, the findings of our survey suggest we have reached a plateau. Looking at savings,\n","for example, the share of people who expect to make regular savings this year is just over 70%,\n","broadly similar to last year. Over half of those saving plan to use some of the funds for residential\n","property. A third are saving for a deposit, and a further 20% for an investment property or second home.\n","\n","But for some, their plans are being pushed back. 9% of respondents stated they had planned to purchase\n","a new home this year but have now changed their mind. While for many the deposit may be an issue,\n","the other driving factor remains the cost of the mortgage, which has been steadily rising the last\n","few years. For those that currently own a property, the survey showed that in the last year,\n","the average mortgage payment has increased from £668.51 to £748.94, or 12%.\"\"\"\n"],"metadata":{"id":"8I7ZsP3OxL-n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = \"\"\"\n","How much has the average mortage payment increased in the last year?\n","\"\"\"\n","\n","prompt = f\"\"\"\n","Using the following context information below please answer the following question\n","to the best of your ability\n","Context:\n","{report}\n","Question:\n","{question}\n","Answer:\n","\"\"\""],"metadata":{"id":"dAPf8hD2xATM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":46},"id":"whY2mBoXxUPM","outputId":"8fed1acf-ebd9-4115-f07a-a7470f31f665"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The average mortgage payment has increased by £80.43, from £668.51 to £748.94, which is a 12% increase."},"metadata":{}}]},{"cell_type":"code","source":["question = \"\"\"\n","What percentage of people had an increase in salary last year? Show the answer just as a number.\n","\"\"\"\n","\n","prompt = f\"\"\"\n","Using the following context information below please answer the following question\n","to the best of your ability\n","Context:\n","{report}\n","Question:\n","{question}\n","Answer:\n","\"\"\"\n","response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":46},"id":"A-Dxn9d_xibD","outputId":"9de744db-d12a-48fd-834b-3816e158e09f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"54"},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 7: Open-Domain Question Answering\n","\n","Question Answering (QA) is a natural language processing task which involves generating the desired answer for the given question.\n","\n","In the case of open-domain QA, only the question is asked without providing any context or information. Here, the LLM answers the question using the knowledge gained from large volumes of text data during its training. This is basically Zero-Shot QA"],"metadata":{"id":"EuQlsSmWxyCd"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Please answer the following question to the best of your ability\n","Question:\n","What is LangChain?\n","\n","Answer:\n","\"\"\""],"metadata":{"id":"fV2MP4OdyETp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"OSC-IhDmyRYg","outputId":"c36efbe6-5fb6-49ac-aa59-5bc2e532f71f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"LangChain is an open-source framework that enables developers to build applications that combine the power of large language models (LLMs) with traditional software development. It provides a set of tools and libraries that make it easier to integrate LLMs into software applications, allowing developers to build more intelligent and interactive systems.\n\nLangChain was created to address the challenges of working with LLMs, such as managing the complexity of model outputs, handling errors and exceptions, and integrating models with other software components. The framework provides a set of abstractions and APIs that simplify the process of working with LLMs, making it easier for developers to build applications that leverage the power of these models.\n\nSome of the key features of LangChain include:\n\n1. **Model management**: LangChain provides a simple way to manage multiple LLMs, including loading, caching, and switching between models.\n2. **Prompt engineering**: LangChain includes tools for crafting and optimizing prompts, which are the input strings used to query LLMs.\n3. **Output processing**: LangChain provides APIs for processing and manipulating the output of LLMs, including text processing, entity extraction, and more.\n4. **Error handling**: LangChain includes mechanisms for handling errors and exceptions that may occur when working with LLMs.\n5. **Integration with other libraries**: LangChain is designed to be highly extensible and can be easily integrated with other libraries and frameworks.\n\nOverall, LangChain is a powerful tool for building applications that leverage the power of large language models. Its simplicity, flexibility, and extensibility make it an attractive choice for developers looking to build more intelligent and interactive systems."},"metadata":{}}]},{"cell_type":"code","source":["prompt = f\"\"\"\n","Please answer the following question to the best of your ability\n","Question:\n","What is LangGraph?\n","\n","Answer:\n","\"\"\""],"metadata":{"id":"xMX1CcsdMg_C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273},"id":"8-AxYD5AMjk6","outputId":"246d38b0-a588-4388-9935-e9e741e2b0ad"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"LangGraph is an AI-powered language model developed by Meta AI. It is a large language model that can generate human-like text and is designed to be more efficient and scalable than other language models. LangGraph is trained on a massive dataset of text from various sources, including books, articles, and websites, and can be fine-tuned for specific tasks such as language translation, text summarization, and text generation.\n\nLangGraph is notable for its ability to handle long-range dependencies and contextual relationships in language, making it well-suited for tasks that require a deep understanding of language structure and semantics. It is also designed to be more interpretable and explainable than other language models, allowing developers to understand how it arrives at its predictions and decisions.\n\nLangGraph has a wide range of potential applications, including language translation, text summarization, chatbots, and content generation. It is also being explored for its potential to improve language understanding and generation in areas such as education, healthcare, and customer service.\n\nIt's worth noting that LangGraph is a relatively new model, and as such, it is still being researched and developed. However, its potential to improve language understanding and generation makes it an exciting area of research and development in the field of natural language processing."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 8: Document Summarization\n","\n","Document summarization is a natural language processing task which involves creating a concise summary of the given text, while still capturing all the important information."],"metadata":{"id":"tnVmXCZAzyux"}},{"cell_type":"code","source":["doc = \"\"\"\n","Coronaviruses are a large family of viruses which may cause illness in animals or humans.\n","In humans, several coronaviruses are known to cause respiratory infections ranging from the\n","common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS).\n","The most recently discovered coronavirus causes coronavirus disease COVID-19.\n","COVID-19 is the infectious disease caused by the most recently discovered coronavirus.\n","This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n","COVID-19 is now a pandemic affecting many countries globally.\n","The most common symptoms of COVID-19 are fever, dry cough, and tiredness.\n","Other symptoms that are less common and may affect some patients include aches\n","and pains, nasal congestion, headache, conjunctivitis, sore throat, diarrhea,\n","loss of taste or smell or a rash on skin or discoloration of fingers or toes.\n","These symptoms are usually mild and begin gradually.\n","Some people become infected but only have very mild symptoms.\n","Most people (about 80%) recover from the disease without needing hospital treatment.\n","Around 1 out of every 5 people who gets COVID-19 becomes seriously ill and develops difficulty breathing.\n","Older people, and those with underlying medical problems like high blood pressure, heart and lung problems,\n","diabetes, or cancer, are at higher risk of developing serious illness.\n","However, anyone can catch COVID-19 and become seriously ill.\n","People of all ages who experience fever and/or  cough associated with difficulty breathing/shortness of breath,\n","chest pain/pressure, or loss of speech or movement should seek medical attention immediately.\n","If possible, it is recommended to call the health care provider or facility first,\n","so the patient can be directed to the right clinic.\n","People can catch COVID-19 from others who have the virus.\n","The disease spreads primarily from person to person through small droplets from the nose or mouth,\n","which are expelled when a person with COVID-19 coughs, sneezes, or speaks.\n","These droplets are relatively heavy, do not travel far and quickly sink to the ground.\n","People can catch COVID-19 if they breathe in these droplets from a person infected with the virus.\n","This is why it is important to stay at least 1 meter) away from others.\n","These droplets can land on objects and surfaces around the person such as tables, doorknobs and handrails.\n","People can become infected by touching these objects or surfaces, then touching their eyes, nose or mouth.\n","This is why it is important to wash your hands regularly with soap and water or clean with alcohol-based hand rub.\n","Practicing hand and respiratory hygiene is important at ALL times and is the best way to protect others and yourself.\n","When possible maintain at least a 1 meter distance between yourself and others.\n","This is especially important if you are standing by someone who is coughing or sneezing.\n","Since some infected persons may not yet be exhibiting symptoms or their symptoms may be mild,\n","maintaining a physical distance with everyone is a good idea if you are in an area where COVID-19 is circulating.\"\"\""],"metadata":{"id":"dY53sXf_ymwE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = f\"\"\"\n","You are an expert in generating accurate document summaries.\n","Generate a summary of the given document.\n","\n","Document:\n","{doc}\n","\n","\n","Constraints: Please start the summary with the delimiter 'Summary'\n","and limit the summary to 5 lines\n","\n","Summary:\n","\"\"\"\n","\n","response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116},"id":"7upxVwh5y8te","outputId":"f88f4e08-c2ab-4634-ba89-ac72a4b541db"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Summary:\nCoronaviruses are a family of viruses that cause respiratory infections in humans, ranging from the common cold to severe diseases like MERS and SARS. \nThe most recently discovered coronavirus causes COVID-19, a pandemic affecting many countries globally. \nCommon symptoms of COVID-19 include fever, dry cough, and tiredness, with most people recovering without hospital treatment. \nHowever, older people and those with underlying medical problems are at higher risk of developing serious illness. \nPracticing hand and respiratory hygiene, maintaining a physical distance, and seeking medical attention immediately if symptoms worsen are crucial in preventing the spread of COVID-19."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 9: Transformation\n","\n","You can use LLMs to take an existing document and transform it into other formats of content and even generate training data for fine-tuning or training models"],"metadata":{"id":"keC5k5S-18cw"}},{"cell_type":"code","source":["fact_sheet_mobile = \"\"\"\n","PRODUCT NAME\n","Samsung Galaxy Z Fold4 5G Black\n","​\n","PRODUCT OVERVIEW\n","Stands out. Stands up. Unfolds.\n","The Galaxy Z Fold4 does a lot in one hand with its 15.73 cm(6.2-inch) Cover Screen.\n","Unfolded, the 19.21 cm(7.6-inch) Main Screen lets you really get into the zone.\n","Pushed-back bezels and the Under Display Camera means there's more screen\n","and no black dot getting between you and the breathtaking Infinity Flex Display.\n","Do more than more with Multi View. Whether toggling between texts or catching up\n","on emails, take full advantage of the expansive Main Screen with Multi View.\n","PC-like power thanks to Qualcomm Snapdragon 8+ Gen 1 processor in your pocket,\n","transforms apps optimized with One UI to give you menus and more in a glance\n","New Taskbar for PC-like multitasking. Wipe out tasks in fewer taps. Add\n","apps to the Taskbar for quick navigation and bouncing between windows when\n","you're in the groove.4 And with App Pair, one tap launches up to three apps,\n","all sharing one super-productive screen\n","Our toughest Samsung Galaxy foldables ever. From the inside out,\n","Galaxy Z Fold4 is made with materials that are not only stunning,\n","but stand up to life's bumps and fumbles. The front and rear panels,\n","made with exclusive Corning Gorilla Glass Victus+, are ready to resist\n","sneaky scrapes and scratches. With our toughest aluminum frame made with\n","Armor Aluminum, this is one durable smartphone.\n","World’s first water resistant foldable smartphones. Be adventurous, rain\n","or shine. You don't have to sweat the forecast when you've got one of the\n","world's first water-resistant foldable smartphones.\n","​\n","PRODUCT SPECS\n","OS - Android 12.0\n","RAM - 12 GB\n","Product Dimensions - 15.5 x 13 x 0.6 cm; 263 Grams\n","Batteries - 2 Lithium Ion batteries required. (included)\n","Item model number - SM-F936BZKDINU_5\n","Wireless communication technologies - Cellular\n","Connectivity technologies - Bluetooth, Wi-Fi, USB, NFC\n","GPS - True\n","Special features - Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, Water Resistant\n","Other display features - Wireless\n","Device interface - primary - Touchscreen\n","Resolution - 2176x1812\n","Other camera features - Rear, Front\n","Form factor - Foldable Screen\n","Colour - Phantom Black\n","Battery Power Rating - 4400\n","Whats in the box - SIM Tray Ejector, USB Cable\n","Manufacturer - Samsung India pvt Ltd\n","Country of Origin - China\n","Item Weight - 263 g\n","\"\"\""],"metadata":{"id":"ta182I2t2FD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt =f\"\"\"Turn the following product description into a list of frequently asked questions (FAQ).\n","Show both the question and it's corresponding answer.\n","Create at the max 8 FAQs\n","\n","Product description:\n","```{fact_sheet_mobile}```\n","\"\"\"\n","\n","response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"zko53u-N2KmD","outputId":"50e73a34-daa7-424e-e7d9-8d799546c75f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Here are 8 FAQs based on the product description:\n\n1. **Q: What are the screen sizes of the Samsung Galaxy Z Fold4 5G?**\nA: The Galaxy Z Fold4 has a 15.73 cm (6.2-inch) Cover Screen and a 19.21 cm (7.6-inch) Main Screen when unfolded.\n\n2. **Q: What processor powers the Samsung Galaxy Z Fold4 5G?**\nA: The Galaxy Z Fold4 is powered by a Qualcomm Snapdragon 8+ Gen 1 processor.\n\n3. **Q: Is the Samsung Galaxy Z Fold4 5G water-resistant?**\nA: Yes, the Galaxy Z Fold4 is one of the world's first water-resistant foldable smartphones.\n\n4. **Q: What is the RAM capacity of the Samsung Galaxy Z Fold4 5G?**\nA: The Galaxy Z Fold4 has 12 GB of RAM.\n\n5. **Q: What operating system does the Samsung Galaxy Z Fold4 5G run on?**\nA: The Galaxy Z Fold4 runs on Android 12.0.\n\n6. **Q: What are the special features of the Samsung Galaxy Z Fold4 5G?**\nA: The Galaxy Z Fold4 has Fast Charging Support, Dual SIM, Wireless Charging, Built-In GPS, and is Water Resistant.\n\n7. **Q: What is included in the box with the Samsung Galaxy Z Fold4 5G?**\nA: The box includes a SIM Tray Ejector and a USB Cable.\n\n8. **Q: What is the battery power rating of the Samsung Galaxy Z Fold4 5G?**\nA: The Galaxy Z Fold4 has a battery power rating of 4400mAh."},"metadata":{}}]},{"cell_type":"markdown","source":["## Task 10: Translation\n","\n","You can use LLMs to take an existing document and translate it from a source to target language. You can also translate to multiple languages at the same time"],"metadata":{"id":"53QdnJ0M3Vee"}},{"cell_type":"code","source":["prompt = \"\"\"You are an expert translator.\n","Translate the given text from English to German and Spanish.\n","\n","Text: 'Hello, how are you today?'\n","Translation:\n","\"\"\"\n","\n","response = get_completion(prompt)\n","display(Markdown(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"g-jdFJqJ2cWu","outputId":"812d04a4-9899-43e8-c8b5-04634046ebc7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Here are the translations of the given text:\n\n- German: 'Hallo, wie geht es Ihnen heute?'\n- Spanish: 'Hola, ¿cómo estás hoy?'"},"metadata":{}}]}]}